Statistics Academic Outline 6/28/17

Basic Definitions:
-StatisticS: the study of methods for collecting, organizing, and analyzing data
	-Descriptive Statistics: procedures used to organize and present data in a convenient and communicable form
	-Inferential Statistics: procedures employed to arrive at broader conclusions or inferences about populations on the basis of samples
-Population: the complete set of actual or potential elements about which inferences are made
-Sample: a subset of the population selected using some sampling method
	-Sampling Methods:
		-cluster sample: a population is divided into groups called clusters; some clusters are randomly selected, and every member in them is observed
		-stratified sample: the population is divided into strat, and a fixed number of elements of each stratum are selected for the sample
		-simple random sample: a sample selected so that each possible sample of the same size has an equal probability of being selected; used for most elementary inference
-Variable: an attribute of elements of a population or sample that can be measured (height, weight, etc.)
	-categorical -- variables that maintain a limited set of possible values -- (meals of the day{breakfast, lunch, dinner})
	-continuous -- variables that are not limited in what values they can have or have a large number of possible values
-Types of measurements:
	-univariate: one measurement per object
	-bivariate: two measures per object
-Data: values of variables that have been observed
	-Types of data:
		-qualitative: descriptive but not numeric
		-quantitative: have numeric values
		-discrete: take counting numbers as values usually representing data that can be counted (rating{0:10})
		-continuous: can take a range of numeric values, not just counting numbers (numbers with decimals, weights of a bag of rice)
	-Levels of measurement:
		-qualitative levels:
			-nominal: values are simply named without order (color of a bean)
			-ordinal: values have some natural order (grades in school)
		-quantitative levels:
			-interval: numeric data with no natural zero point (intervals are meaningful ratios are not (range of temperature {32F:100F}))
			-ratio: numeric data for which there is a true zero; both intervals and ratios are meaningful (weight, length, duration, most physical properties)
-Statistic: a numeric measurement computed from sample dta, used to deescribe the sample and to extimate the corresponding population parameter
-Parameter: a numeric measurement that describes a population; parameters are usually not computed, but are inferred from sample statistics

-Types of Descriptive Methods:
	-tabular: frequency distribution table -- gives all possible values of variables and their frequencies
		-frequency of a value, usually denoted with "f"
		-relative frequency of a value -- ratio of the frequency to the total number of values
		-cumulative frequency -- the number of observations less than or equal to a specified value -- usually denoted "cf"
	-graphical: barcharts, pie charts (use each percent as 3.6 degrees of chart)
		-examining graphs:
			-center, spread (using ranges and broadness/narrowness), shape (symmetric, left-skewed, right-skewed)
			-clusters and gaps -- observe groupings of data
			-outliers -- any observation that is surprisingly different
	-numerical
-Frequency Distributions: proveds the frequency (number of observations) or each value of a variable
	-Grouped Frequency Distributions: values of the variable are grouped into classes
	-Relative Frequency Distributions: each frequency is divided by the total number of observations to produce the proportion or percentage of the data set having that value
	-Cumulative Frequency Distribution: frequencies account all observations at a particular value or class and all those less
	
-Measurements of Central Tendency:
	-Mean: most commonly used measure of central tendency, usually meant by "average", sensitive to extreme values
		-population mean is calculated separately from sample mean with parallel formulas
		-population mean -- greek letter mu || sample mean -- uppercase X with bar over it
			mean = (1/(total number in population or sample))*(sum of all values in population or sample)
		-trimmed mean: computed discarding some number of the highest and lowest values; less sensitive than ordinary mean
		-weighted mean: computed with a weight multiplied by each value , making some values influence the mean more heavily than others
	-Median: value that divides the set so the same number of observations lie on each side of it; less sensitive to extreme values; for an odd number of values, it is the middle value; for an even number, it is the average of the middle two
	-Mode: observation that occurs with the greatest frequency

-Measures of Dispersion:
	-sum of squares (SS): the sum of squared deviations from the mean:
		-can be by population or sample
			SS: (sum of all values in a sample or population minuse the sample or population mean)**2 || ((sum of all values in a sample or population squared)-((sum of all values in sample or population squared)/(number of values in sample or population))
	-variance: the average of square differences between observations and their mean
		-can be by population or sample
			-variance of population = (1/total number in population)*((sigma on all values in population - population mean)**2)
			-variance of sample = (1/(total number in sample - 1)) * ((sigma on all values in sample - sample mean)**2)
		-can also be specified for grouped data:
			-population grouped variance = (1/total number in population)*(sigma on ((f sub i) * (value in population - population mean))**2)
			-sample grouped variance = (1/(total number in sample - 1))*(sigma on ((f sub i) * (value in sample - sample mean))**2)
	-standard deviation: the square root of the variance; unlike variance, it has the same units as the original data and is more commonly used
		-population SD: square root((1/total number in population)*(sigma on (all values in population - population mean)**2)
	-standard scores: also known as z-scores; teh standard score of a value is the directed number of standard deviations form the mean at which the value is found -- z = ((value - respective mean)/(respective deviation)
		-positive z score indicates a value greater than the mean -- negative z score indicates a value less than the mean -- z score of 0 indicates matching the mean
		-converting every value in a data set or distribution to a z score is called standardization
			-once a data set or distribution has been standardized, it has a new mean = 0, and a new standard deviation of 1

-Graphing Techniques:
	-Bar Graph: a graph that uses bars to indicate the frequency of occurrence of observations
		-histogram: a bar graph used with quantitative, continuous variables
	-Frequency Curve: a graph representing a frequency distribution in teh form of a continuous line that traces a histogram
		-cumulative frequency curve: a graph representing a frequency distribution in the form of a continuous line that traces a histogram
		-symmetric curve: the frequency curve is uncahnged if rotate around its center; median = mean
		-normal curve: bell-shaped curve; symmetric
		-skewed curve: deviates fomr symmetry; frequency curve is shifted with a loger tail to the left (mean < median) or to the right (mean > median)
Probability: a measure fo the likelihood of a random event; the long-term relative frequency wiht which an outcome or event occurs
	-formula: probability of occurences(A) = number of outcomes favoring event A / total number of outcomes
	-sample spaces: all possible simple outcomes of an experiment
	-relationships between events:
		-exhaustive: 2 or more events are said to be exhaustive if they represent all possible outcomes
			- P(A|B|C...) = 1
		-non-exhaustive: 2 or more events are said to be non-exhaustive if they do not represent all possible outcomes
		-mutually exclusive: events that cannot occur simultaneously -- P(A&B) = 0 and P(A||B) = P(A)+P(B)
		-non-mutually exclusive: events that can occur simultaneously -- P(A||B) = P(A)+P(B)-P(A&B)
		-independent: events whos probability is unaffected by occurrence or nonoccurrence  of each other 
			P(A||B) = P(A) or P(A||B) = P(B) or P(A&B) = P(A)*P(B)
Graphical Methods for Continuous Variables:
		-Dotplots: (parallel to line ruler)
			1) draw a horizontal line (x-axis) to indicate data range
			2) scale the line to accomodate entire range or note outliers if trimmed
			3) mark a dot for each oservation in the appropriate place above the scaled line
			4) if more than one observation has the same value, add dots on top (one above the other)
			-each dot indicates location of value at that point
			-observations are useful in viewing: data spread, shape of collective data, approximate center of distribution
		-Stemplots: (also stem-and-leaf plots, when turned on it's side it resembles a histogram)
			-shows every value but inconvenient on large data sets
			1) separate each observation into two parts -- left is stem, right is leaf
				-use reasonable number of stems
			2) draw a vertical line on the left side of the page to separate stems and leaves
			3) write outall possible stems in increasing order on the left of the line to ensure entire range of data is covered
			4) for each observation write the leaf to the right of the corresponding stem on the right side of the vertical line
			5) after leaves are created for all observations write all leaves with the same stem in increasing order
			-observations are useful when viewing: how variable is spread (rotate 90 degrees), shape of distribution of the variable, center of the variable
			-special type to compare two boxplots -- back-to-back stem plot
		-Histograms: (looks like a stem plot on its side, useful on large data sets -- not useful on small data sets, pattern within data group is lost but overall pattern remains visible)
			1) create groups of equal length
			2) draw the x and y axes 
			3) scale the x-axis to accomodate large data groups
			4) scale the y-axis to accomodate the range of frequencies used (or relative frequencies or percentages)
			5) draw bars of heights equal to corresponding frequences and add a label for each group 
				-draw bars without gaps in-between
			-most popular way to display data
		-Cumulative Frequency Charts: frequency of that group plus sum of all frequencies up to that observation or group (also called ogive chart)
			1) draw the x and y axes
			2) scale the x-axis to accomodate the range of all groups, mark the upper boundary of each group
			3) scale the y-axis {0:n} for a cumulative frequency ({0:1} for relative frequency)
			4) draw point at height equal to the cumulative frequency for that group above the upper bound
			-symmetric resembles S, right-skewed is above symmetric to the left, left-skewed is below symmetric to the right
		-Boxplots: also box-and-whisper plot -- graphical data summary based on measures of position
			-useful in identifying outliers and general shape of the distribution
			1) draw a horizontal number line
			2) scale the number line to cover the range of observations
			3) draw a regular box above the line from teh first ot the third quartiles
			3) draw a vertical line at the MEDIAN to divide the two components
			4) computer the "whisker" length = ((3/2)*IQR = WL
			5) Compute lower whisker = Q1 - WL, upper whisker = Q3 + WL
			6) make a lower and upper whisker by the smallest and largest values connected to Q1 and Q3 respectively
			7) plot any points larger or smaller than U or L above or below U or L
		-Multiple Frequency Polygrams: (Line Graphs)
			1) connect points to top of bars in a histogram
	-Describing a distribution:
		-when examining a graphical summary of a distribution of univariate data use the following three measures to describe the data:
			-center, spread, shape
			-additionally not clustering, gaps, and any outliers -- provide explanations if possible
Numerical Measures:
	-measures of central tendency (mean, median, mode)
	-measures of variation (standard deviation, variance, range, interquartile range, standard deviation (distance from mean -- 0 means all measurements uniform -- larger indicates larger spread))
	-measures of position (quartiles (1--25%,2--50%,3--75%), percentiles (divide set of values into 100 equal parts (see below)), standardized z-scores (distance between a number and the mean in terms of the standard deviation((measurement-mean)/standard deviation))
		-percentiles -- n measurements, kth percentile, formula on exact percentile {0:100} = ((n+1)*k)/100
	-effects of changing units on summary measures
		-addition: adds to mean, median, and quartiles, does not change range, standard deviaiton, or interquartile range
		-multiplication: multiplies all -- mean, median, range, standard deviation (absolute value only), quartiles, and interquartile range
Comparing Distributions of 2+ groups:
	-compare the centers of the distributions
	-compare the spread -- both inter and intra
	-clusters of measurements and gaps in measurements
	-outliers and any other unusual features
	-compare the shapes of the distributions
Exploring Bivariate Data:
	-bivariate data: collected on two different variables from each item in a study
	-two common summaries:
		-scatterplot -- graphical representation
			-used to describe nature, dgree, and direction of the relation between two variables
			1) draw the x and y axes
			2) scale the x axis to accomodate range of first variable
			3) scale y axis to accomodate range of other variable
			4) for each pair of measurements, mark the point on the graph where the x and y values intersect
			-here is what can be derived about relationship of two variables:
				-shape -- linear or nonlinear
				-direction -- shows whether y value increases or decreases as x increases or that it changes direction
				-strength of relationship -- linear regression, allows to determine correlation
					-close points -- strong
					-some scattered -- weak
					-no pattern -- no relationship
		-correlation coefficient -- numerical representation
Correlation Coefficient: numerical measure used to judge the linear relation between two variables -- does not work well with nonlinear
	-Pearson's correlation coefficient (usually just correlation coefficient) is a numeric measure of the degree and direction of the linear relaion between two quantitative variables
		-population represented by rho in greek alphabet || sample represented by "r"
			-range = {-1:1} always
		-indicates direction (positive (x increase, y increaases linearly) or negative(x increase, y decreases linearly))
		-indicates strength:
			-- 1 indicates perfect positive correlation
			-- -1 indicates perfect negative
			-- close to 1 or -1 -- strong
			-- close to 0 -- weak
			-- 0 -- no relationship
			-- not close to 0 indicates stronger relationship
	-Least Squares Regression Line: useful in predicting corresponding values of one variable for known values of the other variable
		-linear regression model or linear regression equation gives a straight line relationship between two variables
			y = (x*m) + b + e
			-y is the dependent variable or response variable
			-m is the slope
			-b is the y-intercept
			-x is the independent variable
			-e is the random error or residual
		-predicted valeu of y is denoted by "y hat"
			-computed using the regression line: y hat = a + bx
				-a is the y-intercept of regression line
				-b is the estimated slope of regression line
			-residual ^^^ e is computed by y-"y hat"
		-least square regression line minimizes teh error sum of squares of the residuals
			-line of best fit -- always passes through average of x and y as a point -- ("x bar, y bar")
		-coefficient of determination -- measures the percent of variation in y-values explained by the linear relation between x and y values
			-percent variation in y values attributable to percent variation in x values
			-denoted R**2
				-in linear regression is equal to the square of Pearson's coefficient
		-outliers and influential points 
			-outlier -- suprprisingly different from the rest of the data
			-influential observation -- strongly affects a statistic
		-residual plot: a plot of residuals versus the predicted values of y -- used to assess the fit of the model
			-any trends in residual indicate that linear model is not accurate
-Transforms to achieve linearity
	-nonlinear models
	-transformation of the relation -- example) y=(a*(X**b)) -- natural log can be taken of both sides
		-square root is the most commonly applied power transformation
		-other examples:
			-log transformation -- used to linearize the regression model when the relaionship between y adn x suggests a model with a consistently increasing slope
			-square root transformation -- used when the spread of the observation increases with the mean
			-reciprocal transformation -- used to minimize effects of large values of x
			-squre transformation -- used when the slope of the relation consistently decreases as the independent variable increases
			-power transformation -- used if the relationship between dependent and independent variables is modeled by y=(a*(X**b))
-Exploring Categorical Data: Frequency Tables
	-r categories of classification in criterion 1 and c categories of classification in criterion 2 -- known as r * c contigency table
	-joint frequency -- of two categories is the frequency with which two categories, one from each of the two classification criteria, occur
		-row and column totals yield marginal frequencies with which each category occurs
-Conditional Relative Frequencies and Association
	-conditional relative frequency -- relative frequency of one category given that the other category has occurred
		-determines if association exists between the two classification criteria
	-association -- measures degree of relation between categorical variables
		-if there is no assocation between two criteria the number of measurements in a given cell of the contingency table is equal to:
			((row total)*(column total))/total number of measurements
				-if value is greater than observed, there is a negative association
				-if value is less than observed, there is a positive association

-Overview of methods of data collection
	-terms:
		-population: the entire group of individuals or items that we are interested in
		-frame: list of all members of the population
		-sample: part of the population that is actually being examined
		-sample survey: process of collecting information out of a sample
		-censue: process of collecting information from all units in a population
	-experiments and observational studies:
		-experiment: a planned activity that results in measurements (data or observations) 
			-experimenter creates differences in the variable involved in the study and then observes the effects of such differences on the resulting measurements
		-observational study: activity in which the experimenter observes the relationships among variables rather than creating them
	-planning and conducting surveys:
		-biased sample method: result in values that are systematically different from the population values or systematically favor certain outcomes
			-judgemental sampling -- non-random approach, samples of convenience, volunteer samples
	-simple random sampling -- process of obtaining a sample from a population in which each member has an equal chance of being selected
		-sampling with replacement from a finite population -- drawing cards after returning them to deck
		-sampling without replacement from an infinite (or large compared to sample size) population -- selecting voters from a voter registry in a city
		-selected with a single blind method -- population does not know who is selected but surveyor knows algorithm of survey
	-other methods of random sampling:
		-systematic sampling-- first item is selected at random from teh first k items in a set and then every kth item is included in the sample
		-stratified random sampling -- population is divided into groups called strata (singular is stratum) and a simple random sample is selected from each stratum 
			-stratum are homogenous parts of population units
		-proportional sampling -- population is divided into strat and a simple random sample of size proportional to stratum size is selected from each stratum 
		-cluster sampling -- a population is divided into nonhomogenous groups called clusters and a simple ranodm sample is obtained from some clusters, but not necessarily all

-Bias in surveys
	-sampling error -- variation inherent in any survey -- outcome is never uniform in sampling due to dynamic nature of majority of populations
	-response bias -- caused by behavior of interveiwer or respondent -- personal bias violates objectivity (someone not wanting to admit to smoking in high school)
	-nonresponse bias -- no contact or answer refusal
	-undercoverage bias -- part of population is left out of selection
	-wording effect bias -- potential subjective wording could distort survey objectivity

-Planning and Conducting experiments
	-response (dependent) variable is the variable to be measured
	-explanatory (independent) variable explains difference in responses (usually known variable that changes over time to elicit a response's response)
	-experimental unit -- smallest unit of population to which treatment is applied
	-confounding variable -- variable whose effect on the response cannot be separated from the explanatory variable
	-factor -- variable whose effect on the response is of interest in the experiment
		-qualitative or quantitative (categorical or numeric in value)
		-levels -- values of factors in an experiment
		-treatments -- factor-level combinations used in the experiment
	-control group -- group of experimental units similar to all other experimental units except that it is not given any treatment
	-placebo group -- group given fake treatment involving medication
	-single and double blind:
		-blinding technique -- used in medical experiments to prevent such a bias
		-single-blind -- either surveyed OR surveyor do not know which treatment is given
		-double-blind -- surveyed AND surveyor do not know which treatment is given
	-randomization should be implemented in both treatment on groups of population and order of treatments 
	-blocking -- control effects of unknown factors
		-block -- group of homogenous experimental units
	-replication -- process of giving a certain treatment numerous times in an experiment or of applying it to a number of different experimental units and getting similar results
	-completely randomized design -- treatments are assigned to all experimental units or expermental units are assigned randomly to all treatments
	-randomized block design: grouping yields better results
		-randomized paired comparison design -- used when only two treatments are present
			-can be implemented in two ways:
				-matched pair design -- groups are assigned by tossing a coin
				-experimental units are used as their own blocks
